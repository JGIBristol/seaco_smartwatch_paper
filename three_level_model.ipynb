{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "plot_dir = \"outputs/imgs/three_level/\"\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a dataframe showing how many prompts and responses each user had per day, grouping nearby prompts so\n",
    "that we have the expected (roughly) 12 prompts per day.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from analysis_utils import clean\n",
    "\n",
    "\n",
    "def collapse_meal_info(meal_df: pd.DataFrame, delta: pd.Timedelta) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Find the meal entries that are close enough to each other to be responses to the same prompt.\n",
    "\n",
    "    Must have a \"responded?\" column that is 1 if the prompt was responded to, and 0 otherwise.\n",
    "    Successive entries that are less than delta apart and have the same \"responded?\" value are considered to\n",
    "    be a response to the same prompt.\n",
    "\n",
    "    :param meal_df: a dataframe with a DateTimeIndex that includes an \"reponded?\" column\n",
    "    :param delta: the maximum time difference between two entries for them to be considered the same prompt\n",
    "\n",
    "    \"\"\"\n",
    "    collapsed_meal_info = pd.DataFrame()\n",
    "\n",
    "    for _, group in meal_df.groupby(\"p_id\"):\n",
    "        assert group.index.is_monotonic_increasing\n",
    "\n",
    "        # Mark which ones are near enough each other to be considered the same\n",
    "        n_entries = len(group)\n",
    "        keep = np.ones(n_entries, dtype=bool)\n",
    "\n",
    "        for i in range(1, n_entries):\n",
    "            if (group.index[i] - group.index[i - 1] < delta) and (\n",
    "                group[\"responded?\"].iloc[i] == group[\"responded?\"].iloc[i - 1]\n",
    "            ):\n",
    "                keep[i] = False\n",
    "\n",
    "        # Append to the new dataframe\n",
    "        collapsed_meal_info = pd.concat([collapsed_meal_info, group[keep]])\n",
    "\n",
    "    return collapsed_meal_info\n",
    "\n",
    "\n",
    "# Read the smartwatch entries\n",
    "meal_info = clean.cleaned_smartwatch(keep_catchups=False, keep_day0=False)[\n",
    "    [\"p_id\", \"delta\", \"meal_type\"]\n",
    "]\n",
    "\n",
    "# Turn meal type into a binary variable for whether it was a response or non-response\n",
    "meal_info[\"responded?\"] = (\n",
    "    meal_info[\"meal_type\"].isin({\"Meal\", \"Drink\", \"Snack\", \"No food/drink\"}).astype(int)\n",
    ")\n",
    "meal_info.drop(columns=[\"meal_type\"], inplace=True)\n",
    "\n",
    "# Collapse nearby entries of the same type\n",
    "# Using a 27 minute window because that gives us roughly the expected number of prompts per day\n",
    "# Using a larger time window doesn't change anything; using a smaller time window leaves us with some\n",
    "# days with much more than 12 prompts\n",
    "meal_info = collapse_meal_info(meal_info, pd.Timedelta(minutes=27))\n",
    "\n",
    "# Read the survey data\n",
    "demographic_df = clean.cleaned_survey()[\n",
    "    [\n",
    "        \"residents_id\",\n",
    "        \"respondent_sex\",\n",
    "        \"respondent_ethnicity\",\n",
    "        \"age_dob\",\n",
    "        \"phyactq1\",  # In the last 7 days, how many days did you attend school?\n",
    "        \"smart1_7to9\",  # Did your child participate in the smartwatch study?\n",
    "        \"smart1_10to17\",  # Did you participate in the smartwatch study?\n",
    "    ]\n",
    "]\n",
    "demographic_df.rename(\n",
    "    columns={\n",
    "        \"residents_id\": \"p_id\",\n",
    "        \"age_dob\": \"age\",\n",
    "        \"phyactq1\": \"schooldays\",\n",
    "        \"respondent_sex\": \"sex\",\n",
    "        \"respondent_ethnicity\": \"ethnicity\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Convert sex into 0 or 1 in\n",
    "demographic_df[\"sex\"] -= 1\n",
    "\n",
    "# Merge them into one\n",
    "joined_df = meal_info.reset_index().merge(\n",
    "    demographic_df, left_on=\"p_id\", right_on=\"p_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Only keep participants who wore the smartwatch\n",
    "keep = (joined_df[\"smart1_7to9\"] == 1) | (joined_df[\"smart1_10to17\"] == 1)\n",
    "print(f\"Keeping {len(joined_df.loc[keep, 'p_id'].unique())} participants\")\n",
    "joined_df = joined_df.loc[keep]\n",
    "joined_df.drop(columns=[\"smart1_7to9\", \"smart1_10to17\"], inplace=True)\n",
    "\n",
    "# Turn the age into age groups\n",
    "joined_df[\"age_group\"] = (joined_df[\"age\"] > 12).astype(int)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Find the nearest hour to each entry \"\"\"\n",
    "joined_df[\"old_delta\"] = joined_df[\"delta\"]\n",
    "joined_df[\"delta\"] = joined_df[\"delta\"].dt.round(\"h\")\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" See if there are duplicate entries that have been rounded to the same hour \"\"\"\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "count = 0\n",
    "for (p_id, time), group in joined_df.groupby([\"p_id\", \"delta\"]):\n",
    "    if len(group) > 1:\n",
    "        count +=1\n",
    "        display(group)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the ones where there are both a response and a non-response within 5 min of each other which have been assigned to the same hour\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "FIVE_MIN_SECS = 5 * 60\n",
    "\n",
    "drop_indices = []\n",
    "\n",
    "for (p_id, time), group in joined_df.groupby([\"p_id\", \"delta\"]):\n",
    "    if len(group) > 1:\n",
    "        # We have multiple entries for the same person at the same time\n",
    "        for idx, row in group.iterrows():\n",
    "            # Check if this row is a non response\n",
    "            if row[\"responded?\"] == 0:\n",
    "                # Check if there is a positive response for this participant within 5 minutes\n",
    "                response_times = joined_df[\n",
    "                    (joined_df[\"p_id\"] == p_id) & (joined_df[\"responded?\"] == 1)\n",
    "                ][\"old_delta\"]\n",
    "                diff = abs((response_times - row[\"old_delta\"]).dt.total_seconds())\n",
    "\n",
    "                # If there is, add the index to the list of indices to drop\n",
    "                if (diff < FIVE_MIN_SECS).any():\n",
    "                    drop_indices.append(idx)\n",
    "\n",
    "# Drop the rows\n",
    "print(f\"Dropping {drop_indices}\")\n",
    "joined_df = joined_df.drop(drop_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for (p_id, time), group in joined_df.groupby([\"p_id\", \"delta\"]):\n",
    "    if len(group) > 1:\n",
    "        display(group)\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot a matrix of participants' prompt times\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def entry_matrix(input_data: pd.DataFrame, *, only_responses: bool) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get a matrix showing how many responses/prompts each participant had in each hour.\n",
    "\n",
    "    \"\"\"\n",
    "    n_participants = len(input_data[\"p_id\"].unique())\n",
    "    assert n_participants == 82\n",
    "\n",
    "    # Get the times that we expect to have prompts - i.e. every hour\n",
    "    times = pd.timedelta_range(\n",
    "        start=input_data[\"delta\"].min(), end=input_data[\"delta\"].max(), freq=\"h\"\n",
    "    )\n",
    "\n",
    "    # Make a matrix with the right number of columns (7 x 24), and rows (82)\n",
    "    retval = np.zeros((n_participants, len(times)), dtype=int)\n",
    "\n",
    "    # Iterate over p_ids, checking if they have a prompt in each hour\n",
    "    for row_idx, (p_id, group) in enumerate(input_data.groupby(\"p_id\")):\n",
    "        for _, row in group.iterrows():\n",
    "            # Find the index of the time in the times array\n",
    "            idx = np.searchsorted(times, row[\"delta\"])\n",
    "            if not only_responses or row[\"responded?\"] == 1:\n",
    "                retval[row_idx][idx] += 1\n",
    "\n",
    "    return retval\n",
    "\n",
    "\n",
    "prompt_matrix = entry_matrix(joined_df, only_responses=False)\n",
    "response_matrix = entry_matrix(joined_df, only_responses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display((dict(zip(*np.unique(prompt_matrix, return_counts=True)))))\n",
    "display((dict(zip(*np.unique(response_matrix, return_counts=True)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot them\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "boundaries = np.arange(prompt_matrix.max() + 2) - 0.5\n",
    "colors = plt.cm.tab10.colors[: len(boundaries)]\n",
    "cmap = ListedColormap(colors)\n",
    "norm = BoundaryNorm(boundaries, cmap.N, clip=True)\n",
    "imshow_kw = {\n",
    "    \"aspect\": \"auto\",\n",
    "    \"cmap\": cmap,\n",
    "    \"norm\": norm,\n",
    "    \"filternorm\": False,\n",
    "}\n",
    "axes[0].set_title(f\"Prompts\\n{dict(zip(*np.unique(prompt_matrix, return_counts=True)))}\")\n",
    "axes[0].imshow(prompt_matrix, **imshow_kw)\n",
    "\n",
    "axes[1].set_title(f\"Responses\\n{dict(zip(*np.unique(response_matrix, return_counts=True)))}\")\n",
    "axes[1].imshow(response_matrix, **imshow_kw)\n",
    "\n",
    "axes[0].set_ylabel(\"Participant\")\n",
    "for axis in axes:\n",
    "    axis.set_yticks([])\n",
    "\n",
    "cbar_ax = fig.colorbar(axes[0].imshow(prompt_matrix, **imshow_kw), ax=axes[1])\n",
    "cbar_ax.set_ticks(boundaries[:-1] + 0.5)\n",
    "\n",
    "# Set X ticks\n",
    "times = pd.timedelta_range(\n",
    "    start=joined_df[\"delta\"].min(), end=joined_df[\"delta\"].max(), freq=\"h\"\n",
    ")\n",
    "\n",
    "# Set the x-ticks to the filtered times\n",
    "for axis in axes:\n",
    "    (tick_indices,) = np.where(times.components.hours.isin({12}))\n",
    "    labels = [\n",
    "        f\"Day {time.components.days}\\n12:00\"\n",
    "        for time in times[tick_indices]\n",
    "    ]\n",
    "    axis.set_xticks(tick_indices, labels=labels)\n",
    "\n",
    "\n",
    "fig.savefig(f\"{plot_dir}/prompt_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate a CSV file with the data\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "joined_df[\"hour\"] = joined_df[\"delta\"].dt.components.hours\n",
    "joined_df[\"day\"] = joined_df[\"delta\"].dt.components.days\n",
    "\n",
    "csv_cols = [\n",
    "    \"p_id\",\n",
    "    \"day\",\n",
    "    \"hour\",\n",
    "    \"responded?\",\n",
    "    \"sex\",\n",
    "    \"ethnicity\",\n",
    "    \"schooldays\",\n",
    "    \"age_group\",\n",
    "]\n",
    "summary_df = joined_df[csv_cols]\n",
    "summary_df.rename(columns={\"responded?\": \"response\"}, inplace=True)\n",
    "\n",
    "summary_df.to_csv(\"outputs/data/three_level_data.csv\", index=False)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find some summary stats for the data\n",
    "\n",
    "\"\"\"\n",
    "from scipy.special import logit\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def logit_mean_response(df, group_col):\n",
    "    grouped = df.groupby(group_col)['response'].mean()\n",
    "    return logit(grouped)\n",
    "\n",
    "# Function to bootstrap logit of mean response rate\n",
    "def bootstrap_logit_mean_response(df, group_col, n_bootstraps=1000):\n",
    "    bootstrapped_means = []\n",
    "    for _ in range(n_bootstraps):\n",
    "        sample = resample(df)\n",
    "        bootstrapped_means.append(logit_mean_response(sample, group_col))\n",
    "    bootstrapped_means = pd.DataFrame(bootstrapped_means)\n",
    "    return bootstrapped_means.quantile([0.025, 0.975])\n",
    "\n",
    "logit_day = logit_mean_response(summary_df, 'day')\n",
    "logit_hour = logit_mean_response(summary_df, 'hour')\n",
    "\n",
    "# Bootstrap to estimate uncertainty\n",
    "ci_day = bootstrap_logit_mean_response(summary_df, 'day')\n",
    "ci_hour = bootstrap_logit_mean_response(summary_df, 'hour')\n",
    "\n",
    "display(logit_day)\n",
    "display(logit_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for day\n",
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(\n",
    "    logit_day.index,\n",
    "    logit_day,\n",
    "    yerr=[logit_day - ci_day.loc[0.025], ci_day.loc[0.975] - logit_day],\n",
    "    fmt=\"o\",\n",
    ")\n",
    "ax.set_xlabel(\"Day\")\n",
    "ax.set_ylabel(\"Logit of Mean Response Rate\")\n",
    "ax.set_title(\"Logit of Mean Response Rate by Day\")\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(f\"{plot_dir}/logit_day.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(\n",
    "    logit_hour.index,\n",
    "    logit_hour,\n",
    "    yerr=[logit_hour - ci_hour.loc[0.025], ci_hour.loc[0.975] - logit_hour],\n",
    "    fmt=\"o\",\n",
    ")\n",
    "ax.set_xlabel(\"Hour\")\n",
    "ax.set_ylabel(\"Logit of Mean Response Rate\")\n",
    "ax.set_title(\"Logit of Mean Response Rate by Hour\")\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(f\"{plot_dir}/logit_hour.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "response_rate = summary_df.groupby([\"day\", \"hour\"])[\"response\"].mean().reset_index()\n",
    "pivot_table = response_rate.pivot(index=\"day\", columns=\"hour\", values=\"response\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "sns.heatmap(pivot_table, ax=ax, cmap=\"inferno\", cbar_kws={\"label\": \"Response rate\"})\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(f\"{plot_dir}/heatmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_estimate, sex_err = 0.538021, 0.266238\n",
    "\n",
    "display(f\"Sex odds ratio: {np.exp(sex_estimate)}\")\n",
    "display(\n",
    "    f\"95%CI: [{np.exp(sex_estimate - 1.96 * sex_err)}, {np.exp(sex_estimate + 1.96 * sex_err)}]\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
